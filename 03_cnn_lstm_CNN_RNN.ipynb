{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective:  Train and evaluate a 'CNN + LSTM' and 'CNN + RNN' model for classifying indian classical music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, TimeDistributed, SimpleRNN\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tracks = pickle.load(open('all_tracks.pkl', 'rb'))\n",
    "raag = pickle.load(open('raag.pkl', 'rb'))\n",
    "len(set(raag))\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(raag)\n",
    "le.classes_\n",
    "y = le.transform(raag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into training and validation, test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(np.array(all_tracks),\n",
    "                                                    np.array(y),\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)\n",
    "\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp,\n",
    "                                                y_temp,\n",
    "                                                test_size=0.5,\n",
    "                                                random_state=42,\n",
    "                                                stratify=y_temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[..., np.newaxis]\n",
    "X_val = X_val[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create CNN-LSTM hybrid model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_lstm_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    # CNN layers\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Flatten CNN output\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    # LSTM layers\n",
    "    model.add(LSTM(128, return_sequences=False))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Fully connected layer\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create CNN-RNN hybrid model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_rnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    # CNN layers\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    # Flatten the CNN output to feed into RNN\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "    # Simple RNN layers\n",
    "    model.add(SimpleRNN(128, return_sequences=False))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Fully connected layer\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the CNN + LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 2s/step - accuracy: 0.1222 - loss: 2.7105 - val_accuracy: 0.2189 - val_loss: 2.3652\n",
      "Epoch 2/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 2s/step - accuracy: 0.2611 - loss: 2.3235 - val_accuracy: 0.3379 - val_loss: 2.0625\n",
      "Epoch 3/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 2s/step - accuracy: 0.2916 - loss: 2.1652 - val_accuracy: 0.3379 - val_loss: 1.9741\n",
      "Epoch 4/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 2s/step - accuracy: 0.3295 - loss: 2.0141 - val_accuracy: 0.3827 - val_loss: 1.8624\n",
      "Epoch 5/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 2s/step - accuracy: 0.3620 - loss: 1.8799 - val_accuracy: 0.4480 - val_loss: 1.6885\n",
      "Epoch 6/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 2s/step - accuracy: 0.4185 - loss: 1.7671 - val_accuracy: 0.4873 - val_loss: 1.6561\n",
      "Epoch 7/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 1s/step - accuracy: 0.4416 - loss: 1.6725 - val_accuracy: 0.5010 - val_loss: 1.5717\n",
      "Epoch 8/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 1s/step - accuracy: 0.4805 - loss: 1.5309 - val_accuracy: 0.5533 - val_loss: 1.4026\n",
      "Epoch 9/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m186s\u001b[0m 1s/step - accuracy: 0.5610 - loss: 1.3741 - val_accuracy: 0.5678 - val_loss: 1.3365\n",
      "Epoch 10/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 745ms/step - accuracy: 0.5913 - loss: 1.2683 - val_accuracy: 0.5864 - val_loss: 1.3039\n",
      "Epoch 11/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 1s/step - accuracy: 0.6355 - loss: 1.1335 - val_accuracy: 0.6167 - val_loss: 1.1894\n",
      "Epoch 12/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 1s/step - accuracy: 0.6448 - loss: 1.0961 - val_accuracy: 0.6318 - val_loss: 1.1651\n",
      "Epoch 13/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 1s/step - accuracy: 0.7080 - loss: 0.9085 - val_accuracy: 0.6228 - val_loss: 1.1847\n",
      "Epoch 14/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 999ms/step - accuracy: 0.7200 - loss: 0.8613 - val_accuracy: 0.6511 - val_loss: 1.1113\n",
      "Epoch 15/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m232s\u001b[0m 1s/step - accuracy: 0.7414 - loss: 0.8025 - val_accuracy: 0.6579 - val_loss: 1.0613\n",
      "Epoch 16/50\n",
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 771ms/step - accuracy: 0.7566 - loss: 0.7501 - val_accuracy: 0.6469 - val_loss: 1.1443\n",
      "Epoch 17/50\n",
      "\u001b[1m 32/185\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m48s\u001b[0m 314ms/step - accuracy: 0.7624 - loss: 0.6788"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape = X_train.shape[1:]  \n",
    "num_classes = len(set(y_train))\n",
    "\n",
    "cnn_lstm_model = create_cnn_lstm_model(input_shape, num_classes)\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "history_cnn_lstm = cnn_lstm_model.fit(X_train, y_train,\n",
    "                                      validation_data=(X_val, y_val),\n",
    "                                      epochs=50,\n",
    "                                      batch_size=32,\n",
    "                                      callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the CNN + RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_rnn_model = create_cnn_rnn_model(input_shape, num_classes)\n",
    "\n",
    "history_cnn_rnn = cnn_rnn_model.fit(X_train, y_train,\n",
    "                                    validation_data=(X_val, y_val),\n",
    "                                    epochs=50,\n",
    "                                    batch_size=32,\n",
    "                                    callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate CNN + LSTM model\n",
    "test_loss_cnn_lstm, test_acc_cnn_lstm = cnn_lstm_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"CNN + LSTM Test Accuracy: {test_acc_cnn_lstm:.4f}\")\n",
    "\n",
    "# Evaluate CNN + Simple RNN model\n",
    "test_loss_cnn_rnn, test_acc_cnn_rnn = cnn_rnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"CNN + RNN Test Accuracy: {test_acc_cnn_rnn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'{title} Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'{title} Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(history_cnn_lstm, 'CNN + LSTM')\n",
    "plot_history(history_cnn_rnn, 'CNN + RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
